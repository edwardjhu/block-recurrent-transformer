seed: 48
# training
window_len: 5
batch_size: 64
warmup: 100
gclip: 2
lr: 0.0003
adam_beta1: 0.9
adam_beta2: 0.98
max_updates: 50000
max_recon_updates: 1000
# eval
use_mean: False
# architecture
d_model: 768
d_latent: 32
num_layers: 6
lstm_layers: 4
state_len: 1
bottom_up: False
wandb_tag: lstm
# IO
load_posterior: None #posterior_model_after_recon_32mlp.pt
load_decoder: None #model_after_recon_32mlp.pt